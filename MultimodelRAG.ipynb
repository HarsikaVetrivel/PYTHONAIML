{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj4l46b15EPUZBdUP0l3qQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarsikaVetrivel/PYTHONAIML/blob/main/MultimodelRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Install dependencies\n",
        "!pip install transformers langchain sentence-transformers faiss-cpu accelerate --quiet\n",
        "!pip install torchvision torchaudio --quiet\n",
        "!pip install git+https://github.com/huggingface/llava.git@main --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYQWRlNAJX9v",
        "outputId": "1427803b-fc03-4e81-ced3-7690f43dfff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/huggingface/llava.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-ddzo1fbp\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/huggingface/llava.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-ddzo1fbp\u001b[0m did not run successfully.\n",
            "\u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Install required packages\n",
        "!pip install transformers sentence-transformers faiss-cpu Pillow --quiet\n",
        "\n",
        "# ‚úÖ Imports\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "# üß† Load embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# üìÑ Some example documents (text + captions)\n",
        "docs = [\n",
        "    \"Chest X-ray shows bilateral infiltrates and possible pneumonia.\",\n",
        "    \"MRI of the brain reveals no abnormality.\",\n",
        "    \"This image contains a cat sitting on a windowsill looking outside.\",\n",
        "    \"CT scan shows lung nodules suggestive of metastasis.\"\n",
        "]\n",
        "doc_embeddings = embedder.encode(docs)\n",
        "\n",
        "# üß† Create FAISS index\n",
        "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
        "index.add(np.array(doc_embeddings))\n",
        "\n",
        "# üß† Text QA model (Free, no API key, no torch!)\n",
        "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# üñºÔ∏è Function to generate image caption (simulated)\n",
        "def fake_image_caption(image):\n",
        "    # You can replace this with real captioning later\n",
        "    return \"An X-ray image showing abnormalities in the lungs\"\n",
        "\n",
        "# üß† Main RAG function (Image + Text ‚Üí QA)\n",
        "def multimodal_rag(image_path, question):\n",
        "    # Step 1: Get a caption from the image\n",
        "    caption = fake_image_caption(image_path)\n",
        "    print(\"üñºÔ∏è Image Caption:\", caption)\n",
        "\n",
        "    # Step 2: Retrieve the most relevant context\n",
        "    query_embedding = embedder.encode([caption + \" \" + question])\n",
        "    D, I = index.search(np.array(query_embedding), k=1)\n",
        "    retrieved = docs[I[0][0]]\n",
        "    print(\"üîç Retrieved Context:\", retrieved)\n",
        "\n",
        "    # Step 3: Build prompt\n",
        "    prompt = f\"Context: {retrieved}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Step 4: Use FLAN-T5 to answer\n",
        "    result = qa_model(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
        "    return result\n",
        "\n",
        "# üì∏ Test image\n",
        "img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/image_classification.jpeg\"\n",
        "img_path = \"test.jpg\"\n",
        "with open(img_path, \"wb\") as f:\n",
        "    f.write(requests.get(img_url).content)\n",
        "\n",
        "# üéØ Run the multimodal RAG\n",
        "question = \"What condition does the scan indicate?\"\n",
        "answer = multimodal_rag(img_path, question)\n",
        "\n",
        "print(\"\\nüß† Final Answer:\", answer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45xdOzG7J3LP",
        "outputId": "cd481065-06c9-428d-a1b3-a0ded7dc9df7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Image Caption: An X-ray image showing abnormalities in the lungs\n",
            "üîç Retrieved Context: Chest X-ray shows bilateral infiltrates and possible pneumonia.\n",
            "\n",
            "üß† Final Answer: (iii)\n"
          ]
        }
      ]
    }
  ]
}